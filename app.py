
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from dotenv import load_dotenv
import streamlit as st

load_dotenv()

my_key_openai = st.secrets["mykey_openai"]

llm_openai = ChatOpenAI(api_key = my_key_openai, model = "gpt-4o", temperature=0.2, max_tokens=None)
embeddings = OpenAIEmbeddings(api_key = my_key_openai, model="text-embedding-3-large")


st.set_page_config(page_title="AI Lawyer Chatbot", page_icon="ğŸ¤–", layout="centered")
st.title("AI Lawyer Chatbot :robot_face:")
st.divider()

if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "system", "content": "sÉ™n, hÃ¼quqi mÃ¶vzularÄ± sadÉ™ dildÉ™ izah edÉ™n robotsan."})
    

def get_final_prompt(prompt):

    new_vector_store = FAISS.load_local(
    "faiss_index", embeddings, allow_dangerous_deserialization=True
    )

    retriever = new_vector_store.as_retriever()

    relevant_documents = retriever.invoke(prompt)

    context_data = ""

    for document in relevant_documents:
        context_data = context_data + " " + document.page_content
    
    final_prompt = f"""
    SÉ™nÉ™ bir sual verÉ™cÉ™m vÉ™ cavablandÄ±rmaq Ã¼Ã§Ã¼n AzÉ™rbaycan RespublikasÄ±nÄ±n qanunvericiliyinÉ™ aid mÉ™lumatlar tÉ™qdim edÉ™cÉ™m. CavabÄ± hazÄ±rlayarkÉ™n aÅŸaÄŸÄ±dakÄ± tÉ™limatlara É™mÉ™l et:

    - CavabÄ±nÄ± sadÉ™ dildÉ™ yaz.
    - LazÄ±m olduqda, izahÄ±nÄ± nÃ¼munÉ™ ilÉ™ dÉ™stÉ™klÉ™.
    - CavabÄ± mÃ¼mkÃ¼n qÉ™dÉ™r É™traflÄ± vÉ™ dolÄŸun yaz.
    
    Sual: {prompt}
    MÉ™lumatlar: {context_data}
    """

    return final_prompt

for message in st.session_state.messages[1:]:
   with st.chat_message(message["role"]):
      st.markdown(message["content"])

if prompt := st.chat_input("SualÄ±nÄ±zÄ± yazÄ±n..."):
    st.chat_message("user", avatar="ğŸ‘¨ğŸ»").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        response_text = ""
        response_placeholder = st.empty() 

        for token in llm_openai.stream(st.session_state.messages + [{"role": "user", "content": get_final_prompt(prompt)}]):
            token_content = token.content
            response_text += token_content
            response_placeholder.markdown(response_text) 
    
    st.session_state.messages.append({"role": "assistant", "content": response_text})

st.markdown("<hr>", unsafe_allow_html=True)
st.markdown("Created by **AzÉ™rbaycan RespublikasÄ±nÄ±n MÉ™rkÉ™zi BankÄ±** Â© 2024", unsafe_allow_html=True)


